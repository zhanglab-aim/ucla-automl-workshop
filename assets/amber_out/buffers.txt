--------------------------------------------------------------------------------
Episode:4	Reward:0.7331	R_bias:0.8249	Advantage:[-0.09  0.09 -0.09  0.11  0.16 -0.05 -0.07 -0.09 -0.13 -0.11  0.17 -0.07
  0.17  0.1  -0.09]
	Action:conv1d:{'filters': 32, 'kernel_size': 3, 'activation': 'relu'},avgpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 13, 'activation': 'relu'},flatten:{}
	Prob:[[0.17 0.17 0.17 0.17 0.17 0.17]] || [[0.33 0.33 0.33]] || [[0.14 0.14 0.14 0.14 0.14 0.14 0.14]] || [[0.33 0.33 0.33]]
--------------------------------------------------------------------------------
Episode:5	Reward:0.9549	R_bias:0.8249	Advantage:[ 0.16 -0.07  0.13]
	Action:conv1d:{'filters': 32, 'kernel_size': 7, 'activation': 'relu'},avgpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 7, 'activation': 'tanh'},globalmaxpooling1d:{}
	Prob:[[0.17 0.17 0.17 0.17 0.16 0.16]] || [[0.34 0.32 0.34]] || [[0.14 0.14 0.12 0.13 0.18 0.14 0.15]] || [[0.21 0.21 0.58]]
--------------------------------------------------------------------------------
Episode:6	Reward:0.9218	R_bias:0.8299	Advantage:[ 0.09 -0.23  0.09]
	Action:conv1d:{'filters': 32, 'kernel_size': 3, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 13, 'activation': 'tanh'},globalmaxpooling1d:{}
	Prob:[[0.23 0.28 0.27 0.15 0.03 0.05]] || [[0.8  0.03 0.17]] || [[0.24 0.   0.   0.01 0.65 0.01 0.08]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:7	Reward:0.9562	R_bias:0.8289	Advantage:[0.14 0.13 0.13]
	Action:conv1d:{'filters': 32, 'kernel_size': 7, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 13, 'activation': 'tanh'},globalmaxpooling1d:{}
	Prob:[[0.3  0.46 0.18 0.06 0.   0.  ]] || [[0.89 0.01 0.09]] || [[0.26 0.   0.   0.   0.73 0.   0.01]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:8	Reward:0.9618	R_bias:0.8378	Advantage:[0.12 0.14 0.12]
	Action:conv1d:{'filters': 32, 'kernel_size': 7, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 13, 'activation': 'tanh'},globalmaxpooling1d:{}
	Prob:[[0.3  0.62 0.06 0.02 0.   0.  ]] || [[0.94 0.01 0.05]] || [[0.14 0.   0.   0.   0.86 0.   0.  ]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:9	Reward:0.9834	R_bias:0.8464	Advantage:[0.13 0.14 0.14]
	Action:conv1d:{'filters': 32, 'kernel_size': 13, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 7, 'activation': 'relu'},globalmaxpooling1d:{}
	Prob:[[0.58 0.38 0.03 0.01 0.   0.  ]] || [[0.97 0.   0.03]] || [[0.19 0.   0.   0.   0.81 0.   0.  ]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:10	Reward:0.9836	R_bias:0.8555	Advantage:[0.13 0.13 0.13]
	Action:conv1d:{'filters': 32, 'kernel_size': 13, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 7, 'activation': 'relu'},globalmaxpooling1d:{}
	Prob:[[0.6  0.38 0.02 0.01 0.   0.  ]] || [[0.98 0.   0.02]] || [[0.43 0.   0.   0.   0.57 0.   0.  ]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:11	Reward:0.9835	R_bias:0.8641	Advantage:[0.1  0.09 0.12]
	Action:conv1d:{'filters': 32, 'kernel_size': 7, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 7, 'activation': 'relu'},globalmaxpooling1d:{}
	Prob:[[0.54 0.44 0.01 0.01 0.   0.  ]] || [[0.99 0.   0.01]] || [[0.55 0.   0.   0.   0.45 0.   0.  ]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:12	Reward:0.9812	R_bias:0.8710	Advantage:[0.11 0.09 0.11]
	Action:conv1d:{'filters': 32, 'kernel_size': 13, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 7, 'activation': 'relu'},globalmaxpooling1d:{}
	Prob:[[0.61 0.38 0.01 0.01 0.   0.  ]] || [[0.99 0.   0.01]] || [[0.52 0.   0.   0.   0.48 0.   0.  ]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:13	Reward:0.9400	R_bias:0.8779	Advantage:[0.07 0.11 0.06]
	Action:conv1d:{'filters': 32, 'kernel_size': 7, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 13, 'activation': 'tanh'},globalmaxpooling1d:{}
	Prob:[[0.61 0.37 0.01 0.01 0.   0.  ]] || [[0.99 0.   0.01]] || [[0.54 0.   0.   0.   0.46 0.   0.  ]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:14	Reward:0.9595	R_bias:0.8833	Advantage:[0.1  0.1  0.08]
	Action:conv1d:{'filters': 32, 'kernel_size': 7, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 13, 'activation': 'tanh'},globalmaxpooling1d:{}
	Prob:[[0.61 0.38 0.   0.01 0.   0.  ]] || [[0.99 0.   0.01]] || [[0.53 0.   0.   0.   0.47 0.   0.  ]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:15	Reward:0.9530	R_bias:0.8895	Advantage:[0.07 0.1  0.06]
	Action:conv1d:{'filters': 32, 'kernel_size': 7, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 13, 'activation': 'tanh'},globalmaxpooling1d:{}
	Prob:[[0.61 0.38 0.   0.   0.   0.  ]] || [[1. 0. 0.]] || [[0.55 0.   0.   0.   0.45 0.   0.  ]] || [[0. 0. 1.]]
--------------------------------------------------------------------------------
Episode:16	Reward:0.9505	R_bias:0.8948	Advantage:[0.08 0.06 0.06]
	Action:conv1d:{'filters': 32, 'kernel_size': 7, 'activation': 'relu'},maxpool1d:{'pool_size': 4},conv1d:{'filters': 64, 'kernel_size': 13, 'activation': 'tanh'},globalmaxpooling1d:{}
	Prob:[[0.61 0.38 0.   0.   0.   0.  ]] || [[1. 0. 0.]] || [[0.54 0.   0.   0.   0.46 0.   0.  ]] || [[0. 0. 1.]]
